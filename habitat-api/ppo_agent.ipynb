{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/azav/.local/lib/python3.6/site-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.25.8) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "# Copyright (c) Facebook, Inc. and its affiliates.\n",
    "# This source code is licensed under the MIT license found in the\n",
    "# LICENSE file in the root directory of this source tree.\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "from math import pi\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import orbslam2\n",
    "import PIL\n",
    "import cv2\n",
    "import requests\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import habitat\n",
    "from habitat.config.default import get_config\n",
    "from habitat.sims.habitat_simulator.actions import HabitatSimActions\n",
    "from habitat_baselines.config.default import get_config as cfg_baseline\n",
    "from habitat_baselines.slambased.mappers import DirectDepthMapper\n",
    "from habitat_baselines.slambased.monodepth import MonoDepthEstimator\n",
    "from habitat_baselines.slambased.path_planners import DifferentiableStarPlanner\n",
    "from habitat_baselines.slambased.reprojection import (\n",
    "    get_direction,\n",
    "    get_distance,\n",
    "    habitat_goalpos_to_mapgoal_pos,\n",
    "    homogenize_p,\n",
    "    planned_path2tps,\n",
    "    project_tps_into_worldmap,\n",
    "    angle_to_pi_2_minus_pi_2 as norm_ang,\n",
    ")\n",
    "from habitat_baselines.slambased.utils import generate_2dgrid\n",
    "\n",
    "GOAL_SENSOR_UUID = \"pointgoal_with_gps_compass\"\n",
    "#GOAL_SENSOR_UUID = \"objectgoal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(url, filename):\n",
    "    with open(filename, \"wb\") as f:\n",
    "        response = requests.get(url, stream=True)\n",
    "        total = response.headers.get(\"content-length\")\n",
    "        if total is None:\n",
    "            f.write(response.content)\n",
    "        else:\n",
    "            downloaded = 0\n",
    "            total = int(total)\n",
    "            for data in response.iter_content(\n",
    "                chunk_size=max(int(total / 1000), 1024 * 1024)\n",
    "            ):\n",
    "                downloaded += len(data)\n",
    "                f.write(data)\n",
    "                done = int(50 * downloaded / total)\n",
    "                sys.stdout.write(\n",
    "                    \"\\r[{}{}]\".format(\"â–ˆ\" * done, \".\" * (50 - done))\n",
    "                )\n",
    "                sys.stdout.flush()\n",
    "    sys.stdout.write(\"\\n\")\n",
    "\n",
    "\n",
    "def ResizePIL2(np_img, size=256):\n",
    "    im1 = PIL.Image.fromarray(np_img)\n",
    "    return np.array(im1.resize((size, size)))\n",
    "\n",
    "\n",
    "def make_good_config_for_orbslam2(config):\n",
    "    config.SIMULATOR.AGENT_0.SENSORS = [\"RGB_SENSOR\", \"DEPTH_SENSOR\"]\n",
    "    config.SIMULATOR.RGB_SENSOR.WIDTH = 640\n",
    "    config.SIMULATOR.RGB_SENSOR.HEIGHT = 480\n",
    "    config.SIMULATOR.DEPTH_SENSOR.WIDTH = 640\n",
    "    config.SIMULATOR.DEPTH_SENSOR.HEIGHT = 480\n",
    "    config.ORBSLAM2.CAMERA_HEIGHT = config.SIMULATOR.DEPTH_SENSOR.POSITION[\n",
    "        1\n",
    "    ]\n",
    "    config.ORBSLAM2.H_OBSTACLE_MIN = (\n",
    "        0.3 * config.ORBSLAM2.CAMERA_HEIGHT\n",
    "    )\n",
    "    config.ORBSLAM2.H_OBSTACLE_MAX = (\n",
    "        1.0 * config.ORBSLAM2.CAMERA_HEIGHT\n",
    "    )\n",
    "    config.ORBSLAM2.MIN_PTS_IN_OBSTACLE = (\n",
    "        config.SIMULATOR.DEPTH_SENSOR.WIDTH / 2.0\n",
    "    )\n",
    "    return\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "from examples.habitat_sim_py.utils.common import d3_40_colors_rgb\n",
    "import numpy as np\n",
    "\n",
    "def display_sample(rgb_obs, semantic_obs, depth_obs):\n",
    "    rgb_img = Image.fromarray(rgb_obs, mode=\"RGB\")\n",
    "    \n",
    "    semantic_img = Image.new(\"P\", (semantic_obs.shape[1], semantic_obs.shape[0]))\n",
    "    semantic_img.putpalette(d3_40_colors_rgb.flatten())\n",
    "    semantic_img.putdata((semantic_obs.flatten() % 40).astype(np.uint8))\n",
    "    semantic_img = semantic_img.convert(\"RGBA\")\n",
    "    \n",
    "    depth_img = Image.fromarray((depth_obs * 255).astype(np.uint8), mode=\"L\")\n",
    "\n",
    "    arr = [rgb_img, semantic_img, depth_img]\n",
    "    \n",
    "    titles = ['rgb', 'semantic', 'depth']\n",
    "    plt.figure(figsize=(12 ,8))\n",
    "    for i, data in enumerate(arr):\n",
    "        ax = plt.subplot(1, 3, i+1)\n",
    "        ax.axis('off')\n",
    "        ax.set_title(titles[i])\n",
    "        plt.imshow(data)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomAgent(object):\n",
    "    r\"\"\"Simplest agent, which returns random actions,\n",
    "    until reach the goal\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super(RandomAgent, self).__init__()\n",
    "        self.num_actions = config.NUM_ACTIONS\n",
    "        self.dist_threshold_to_stop = config.DIST_TO_STOP\n",
    "        self.reset()\n",
    "        return\n",
    "\n",
    "    def reset(self):\n",
    "        self.steps = 0\n",
    "        return\n",
    "\n",
    "    def update_internal_state(self, habitat_observation):\n",
    "        self.obs = habitat_observation\n",
    "        self.steps += 1\n",
    "        return\n",
    "\n",
    "    def is_goal_reached(self):\n",
    "        dist = self.obs[GOAL_SENSOR_UUID][0]\n",
    "        return dist <= self.dist_threshold_to_stop\n",
    "\n",
    "    def act(self, habitat_observation=None, random_prob=1.0):\n",
    "        self.update_internal_state(habitat_observation)\n",
    "        # Act\n",
    "        # Check if we are done\n",
    "        if self.is_goal_reached():\n",
    "            action = HabitatSimActions.STOP\n",
    "        else:\n",
    "            action = random.randint(0, self.num_actions - 1)\n",
    "        return {\"action\": action}\n",
    "\n",
    "\n",
    "class BlindAgent(RandomAgent):\n",
    "    def __init__(self, config):\n",
    "        super(BlindAgent, self).__init__()\n",
    "        self.pos_th = config.DIST_TO_STOP\n",
    "        self.angle_th = config.ANGLE_TH\n",
    "        self.reset()\n",
    "        return\n",
    "\n",
    "    def decide_what_to_do(self):\n",
    "        distance_to_goal = self.obs[GOAL_SENSOR_UUID][0]\n",
    "        angle_to_goal = norm_ang(np.array(self.obs[GOAL_SENSOR_UUID][1]))\n",
    "        command = HabitatSimActions.STOP\n",
    "        if distance_to_goal <= self.pos_th:\n",
    "            return command\n",
    "        if abs(angle_to_goal) < self.angle_th:\n",
    "            command = HabitatSimActions.MOVE_FORWARD\n",
    "        else:\n",
    "            if (angle_to_goal > 0) and (angle_to_goal < pi):\n",
    "                command = HabitatSimActions.TURN_LEFT\n",
    "            elif angle_to_goal > pi:\n",
    "                command = HabitatSimActions.TURN_RIGHT\n",
    "            elif (angle_to_goal < 0) and (angle_to_goal > -pi):\n",
    "                command = HabitatSimActions.TURN_RIGHT\n",
    "            else:\n",
    "                command = HabitatSimActions.TURN_LEFT\n",
    "\n",
    "        return command\n",
    "\n",
    "    def act(self, habitat_observation=None, random_prob=0.1):\n",
    "        self.update_internal_state(habitat_observation)\n",
    "        # Act\n",
    "        if self.is_goal_reached():\n",
    "            return HabitatSimActions.STOP\n",
    "        command = self.decide_what_to_do()\n",
    "        random_action = random.randint(0, self.num_actions - 1)\n",
    "        act_randomly = np.random.uniform(0, 1, 1) < random_prob\n",
    "        if act_randomly:\n",
    "            action = random_action\n",
    "        else:\n",
    "            action = command\n",
    "        return {\"action\": action}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ORBSLAM2Agent(RandomAgent):\n",
    "    def __init__(self, config, device=torch.device(\"cuda:0\"), print_attrs=False):\n",
    "        self.num_actions = config.NUM_ACTIONS\n",
    "        self.dist_threshold_to_stop = config.DIST_TO_STOP\n",
    "        self.slam_vocab_path = config.SLAM_VOCAB_PATH\n",
    "        assert os.path.isfile(self.slam_vocab_path)\n",
    "        self.slam_settings_path = config.SLAM_SETTINGS_PATH\n",
    "        assert os.path.isfile(self.slam_settings_path)\n",
    "        self.slam = orbslam2.System(\n",
    "            self.slam_vocab_path, self.slam_settings_path, orbslam2.Sensor.RGBD\n",
    "        )\n",
    "        self.slam.set_use_viewer(False)\n",
    "        self.slam.initialize()\n",
    "        self.device = device\n",
    "        self.map_size_meters = config.MAP_SIZE\n",
    "        self.map_cell_size = config.MAP_CELL_SIZE\n",
    "        self.pos_th = config.DIST_REACHED_TH\n",
    "        self.next_wp_th = config.NEXT_WAYPOINT_TH\n",
    "        self.angle_th = config.ANGLE_TH\n",
    "        self.obstacle_th = config.MIN_PTS_IN_OBSTACLE\n",
    "        self.depth_denorm = config.DEPTH_DENORM\n",
    "        self.planned_waypoints = []\n",
    "        self.mapper = DirectDepthMapper(\n",
    "            camera_height=config.CAMERA_HEIGHT,\n",
    "            near_th=config.D_OBSTACLE_MIN,\n",
    "            far_th=config.D_OBSTACLE_MAX,\n",
    "            h_min=config.H_OBSTACLE_MIN,\n",
    "            h_max=config.H_OBSTACLE_MAX,\n",
    "            map_size=config.MAP_SIZE,\n",
    "            map_cell_size=config.MAP_CELL_SIZE,\n",
    "            device=device,\n",
    "        )\n",
    "        self.planner = DifferentiableStarPlanner(\n",
    "            max_steps=config.PLANNER_MAX_STEPS,\n",
    "            preprocess=config.PREPROCESS_MAP,\n",
    "            beta=config.BETA,\n",
    "            device=device,\n",
    "        )\n",
    "        self.slam_to_world = 1.0\n",
    "        self.timestep = 0.1\n",
    "        self.timing = False\n",
    "        self.reset()\n",
    "        self.needs_inspection = True\n",
    "        self.located_true_goal = False\n",
    "        self.start_location = None\n",
    "        self.start_rotation = None\n",
    "        self.obstacle_ray_map = None\n",
    "        \n",
    "        self.curr_map_info = np.zeros(3)  # loc and rot\n",
    "        \n",
    "        \n",
    "        # print('self', self, dir(self))\n",
    "        self.init_time = int(time.time())\n",
    "        if print_attrs:\n",
    "            for attr_name in dir(self):\n",
    "                if '__' not in attr_name:\n",
    "                    print(attr_name, getattr(self, attr_name), type(getattr(self, attr_name)))\n",
    "                    type_name = str(type(getattr(self, attr_name)))\n",
    "                    if 'numpy' in type_name or 'ensor' in type_name:\n",
    "                        print(getattr(getattr(self, attr_name), 'shape'))\n",
    "        return\n",
    "\n",
    "    def reset(self, map_info=np.zeros(3)):\n",
    "        super(ORBSLAM2Agent, self).reset()\n",
    "        self.offset_to_goal = None\n",
    "        self.tracking_is_OK = False\n",
    "        self.waypointPose6D = None\n",
    "        self.unseen_obstacle = False\n",
    "        self.action_history = []\n",
    "        self.planned_waypoints = []\n",
    "        self.map2DObstacles = self.init_map2d()\n",
    "        n, ch, height, width = self.map2DObstacles.size()\n",
    "        self.coordinatesGrid = generate_2dgrid(height, width, False).to(\n",
    "            self.device\n",
    "        )\n",
    "        self.pose6D = self.init_pose6d()\n",
    "        self.action_history = []\n",
    "        self.pose6D_history = []\n",
    "        self.position_history = []\n",
    "        self.planned2Dpath = torch.zeros((0))\n",
    "        self.slam.reset()\n",
    "        self.cur_time = 0\n",
    "        self.to_do_list = []\n",
    "        self.waypoint_id = 0\n",
    "        \n",
    "        self.curr_map_info = map_info\n",
    "        \n",
    "        if self.device != torch.device(\"cpu\"):\n",
    "            torch.cuda.empty_cache()\n",
    "        return\n",
    "\n",
    "    def update_internal_state(self, habitat_observation):\n",
    "        # sets self.obs = observation\n",
    "        super(ORBSLAM2Agent, self).update_internal_state(habitat_observation)\n",
    "\n",
    "        if self.start_location is None:\n",
    "            self.start_location = habitat_observation['gps']\n",
    "        if self.start_rotation is None:\n",
    "            self.start_rotation = habitat_observation['compass']\n",
    "\n",
    "        self.cur_time += self.timestep\n",
    "        rgb, depth = self.rgb_d_from_observation(habitat_observation)\n",
    "        t = time.time()\n",
    "        try:\n",
    "            self.slam.process_image_rgbd(rgb, depth, self.cur_time)\n",
    "            if self.timing:\n",
    "                print(time.time() - t, \"ORB_SLAM2\")\n",
    "            self.tracking_is_OK = str(self.slam.get_tracking_state()) == \"OK\"\n",
    "        except BaseException as e:\n",
    "            print(\"Warning!!!! ORBSLAM processing frame error\")\n",
    "            print(\"orbslam error:\", e)\n",
    "            self.tracking_is_OK = False\n",
    "        if not self.tracking_is_OK:\n",
    "            print(\"\\n\\n\\n\\nRESETTING MYSELF BC TRACKING NOT OKAY\\n\\n\\n\\n\")\n",
    "            print(\"SLAM TRACKING STATE:\", self.slam.get_tracking_state())\n",
    "            self.reset(np.append(habitat_observation['gps'], habitat_observation['compass']))\n",
    "        t = time.time()\n",
    "        self.set_offset_to_goal(habitat_observation)\n",
    "        if self.tracking_is_OK:\n",
    "            trajectory_history = np.array(self.slam.get_trajectory_points())\n",
    "            self.pose6D = homogenize_p(\n",
    "                torch.from_numpy(trajectory_history[-1])[1:]\n",
    "                .view(3, 4)\n",
    "                .to(self.device)\n",
    "            ).view(1, 4, 4)\n",
    "            self.trajectory_history = trajectory_history\n",
    "            if len(self.position_history) > 1:\n",
    "                previous_step = get_distance(\n",
    "                    self.pose6D.view(4, 4),\n",
    "                    torch.from_numpy(self.position_history[-1])\n",
    "                    .view(4, 4)\n",
    "                    .to(self.device),\n",
    "                )\n",
    "                if self.action_history[-1] == HabitatSimActions.MOVE_FORWARD:\n",
    "                    self.unseen_obstacle = (\n",
    "                        previous_step.item() <= 0.001\n",
    "                    )  # hardcoded threshold for not moving\n",
    "        current_obstacles = self.mapper(\n",
    "            torch.from_numpy(depth).to(self.device).squeeze(), self.pose6D\n",
    "        ).to(self.device)\n",
    "        self.current_obstacles = current_obstacles\n",
    "        self.map2DObstacles = torch.max(\n",
    "            self.map2DObstacles, current_obstacles.unsqueeze(0).unsqueeze(0)\n",
    "        )\n",
    "        if self.timing:\n",
    "            print(time.time() - t, \"Mapping\")\n",
    "        return True\n",
    "\n",
    "    def init_pose6d(self):\n",
    "        return torch.eye(4).float().to(self.device)\n",
    "\n",
    "    def map_size_in_cells(self):\n",
    "        return int(self.map_size_meters / self.map_cell_size)\n",
    "\n",
    "    def init_map2d(self):\n",
    "        return (\n",
    "            torch.zeros(\n",
    "                1, 1, self.map_size_in_cells(), self.map_size_in_cells()\n",
    "            )\n",
    "            .float()\n",
    "            .to(self.device)\n",
    "        )\n",
    "\n",
    "    def get_orientation_on_map(self):\n",
    "        self.pose6D = self.pose6D.view(1, 4, 4)\n",
    "        return torch.tensor(\n",
    "            [\n",
    "                [self.pose6D[0, 0, 0], self.pose6D[0, 0, 2]],\n",
    "                [self.pose6D[0, 2, 0], self.pose6D[0, 2, 2]],\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def get_position_on_map(self, do_floor=True):\n",
    "        return project_tps_into_worldmap(\n",
    "            self.pose6D.view(1, 4, 4),\n",
    "            self.map_cell_size,\n",
    "            self.map_size_meters,\n",
    "            do_floor,\n",
    "        )\n",
    "\n",
    "    def act(self, habitat_observation, random_prob=0.1):\n",
    "        # Update internal state\n",
    "        t = time.time()\n",
    "        cc = 0\n",
    "        update_is_ok = self.update_internal_state(habitat_observation)\n",
    "        while not update_is_ok:\n",
    "            update_is_ok = self.update_internal_state(habitat_observation)\n",
    "            cc += 1\n",
    "            if cc > 2:\n",
    "                break\n",
    "        if self.timing:\n",
    "            print(time.time() - t, \" s, update internal state\")\n",
    "        self.position_history.append(\n",
    "            self.pose6D.detach().cpu().numpy().reshape(1, 4, 4)\n",
    "        )\n",
    "        success = self.is_goal_reached()\n",
    "        if success:\n",
    "            print(\"\\n\\n\\nGOAL IS BELIEVED TO BE REACHED before planning\\n\\n\\n\")\n",
    "            action = HabitatSimActions.STOP\n",
    "            self.action_history.append(action)\n",
    "            return {\"action\": action}\n",
    "        # Plan action\n",
    "        t = time.time()\n",
    "\n",
    "        if len(self.to_do_list) > 0:\n",
    "            # pop from to do list queue\n",
    "            action = self.to_do_list.pop(0)\n",
    "            self.action_history.append(action)\n",
    "            return {\"action\": action}\n",
    "\n",
    "        print(\"\\n\\nTo do list is empty, needs inspection?:\",\n",
    "              self.needs_inspection)\n",
    "        \n",
    "        if self.needs_inspection:\n",
    "            # do a left turn 360\n",
    "            # each turn is 10 degrees\n",
    "            self.to_do_list.extend(\n",
    "                [HabitatSimActions.TURN_LEFT] * 36\n",
    "            )\n",
    "            self.needs_inspection = False\n",
    "\n",
    "        # find a goal and then go to it\n",
    "        # after reaching the goal, get inspection again\n",
    "\n",
    "        self.planned2Dpath, self.planned_waypoints = self.plan_path()\n",
    "        if self.timing:\n",
    "            print(time.time() - t, \" s, Planning\")\n",
    "        t = time.time()\n",
    "        # Act\n",
    "        if self.waypointPose6D is None:\n",
    "            self.waypointPose6D = self.get_valid_waypoint_pose6d()\n",
    "        if (\n",
    "            self.is_waypoint_reached(self.waypointPose6D)\n",
    "            or not self.tracking_is_OK\n",
    "        ):\n",
    "            self.waypointPose6D = self.get_valid_waypoint_pose6d()\n",
    "            self.waypoint_id += 1\n",
    "        action = self.decide_what_to_do()\n",
    "        # May be random? ALEX: LETS NOT\n",
    "#         random_action = random.randint(0, self.num_actions - 1)\n",
    "#         what_to_do = np.random.uniform(0, 1, 1)\n",
    "#         if what_to_do < random_prob:\n",
    "#             action = random_action\n",
    "        if self.timing:\n",
    "            print(time.time() - t, \" s, get action\")\n",
    "        self.action_history.append(action)\n",
    "        if action == 0:\n",
    "            print(\"\\n\\n\\nGOAL IS BELIEVED TO BE REACHED after planning\\n\\n\\n\")\n",
    "        return {\"action\": action}\n",
    "\n",
    "    def is_waypoint_good(self, pose6d):\n",
    "        p_init = self.pose6D.squeeze()\n",
    "        dist_diff = get_distance(p_init, pose6d)\n",
    "        valid = dist_diff > self.next_wp_th\n",
    "        return valid.item()\n",
    "\n",
    "    def is_waypoint_reached(self, pose6d):\n",
    "        p_init = self.pose6D.squeeze()\n",
    "        dist_diff = get_distance(p_init, pose6d)\n",
    "        reached = dist_diff <= self.pos_th\n",
    "        return reached.item()\n",
    "\n",
    "    def get_waypoint_dist_dir(self):\n",
    "        angle = get_direction(\n",
    "            self.pose6D.squeeze(), self.waypointPose6D.squeeze(), 0, 0\n",
    "        )\n",
    "        dist = get_distance(\n",
    "            self.pose6D.squeeze(), self.waypointPose6D.squeeze()\n",
    "        )\n",
    "        return torch.cat(\n",
    "            [\n",
    "                dist.view(1, 1),\n",
    "                torch.sin(angle).view(1, 1),\n",
    "                torch.cos(angle).view(1, 1),\n",
    "            ],\n",
    "            dim=1,\n",
    "        )\n",
    "\n",
    "    def get_valid_waypoint_pose6d(self):\n",
    "        p_next = self.planned_waypoints[0]\n",
    "        while not self.is_waypoint_good(p_next):\n",
    "            if len(self.planned_waypoints) > 1:\n",
    "                self.planned_waypoints = self.planned_waypoints[1:]\n",
    "                p_next = self.planned_waypoints[0]\n",
    "            else:\n",
    "                p_next = self.estimatedGoalPos6D.squeeze()\n",
    "                break\n",
    "        return p_next\n",
    "\n",
    "    def is_goal_reached(self):\n",
    "        if self.obs.get(\"pointgoal_with_gps_compass\") is None:\n",
    "            dist = self.obs[\"explorationgoal\"][0]\n",
    "        else:\n",
    "            dist = self.obs[\"pointgoal_with_gps_compass\"][0]\n",
    "        return dist <= self.dist_threshold_to_stop\n",
    "\n",
    "    \n",
    "    def find_object_goal(self, observation):\n",
    "        \"\"\"\n",
    "        call the object detector and see if the goal is in view. if so, lock it down!\n",
    "        \"\"\"\n",
    "        # return just none for now\n",
    "        return None\n",
    "\n",
    "\n",
    "    def plan_exploration(self, observation):\n",
    "        \"\"\"\n",
    "        If just exploring, shoot rays outwards from current location, and go to the ray\n",
    "        that can go the farthest without hitting and object\n",
    "        \"\"\"\n",
    "        num_rays = 72\n",
    "        curr_rays = [2 * np.pi / num_rays * i for i in range(num_rays)]\n",
    "        dist_step = 0.1\n",
    "        max_dist = 10\n",
    "        location_in_obs_map = (observation['gps'] - self.start_location).astype(int) * 10 + 200\n",
    "\n",
    "        if 'numpy' in str(type(self.map2DObstacles)): \n",
    "            np_obs_map = (self.map2DObstacles > self.obstacle_th).astype(np.uint8)\n",
    "        else:\n",
    "            np_obs_map = (self.map2DObstacles[0,0].cpu().numpy() > self.obstacle_th).astype(np.uint8)\n",
    "\n",
    "        # kernel for image closing\n",
    "        kernel = np.ones((5,5),np.uint8)            \n",
    "        np_obs_map = cv2.morphologyEx(np_obs_map, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "        best_ray = None\n",
    "        best_coord = None\n",
    "        best_dist = None\n",
    "\n",
    "        for n_steps in range(int(max_dist / dist_step)):\n",
    "            curr_dist = n_steps * dist_step\n",
    "            next_rays = []\n",
    "            for ray in curr_rays:\n",
    "                y_coord = int(np.cos(ray) * curr_dist * 10 + location_in_obs_map[0])\n",
    "                x_coord = int(-np.sin(ray) * curr_dist * 10 + location_in_obs_map[1])\n",
    "                if np_obs_map[y_coord, x_coord] != 1:\n",
    "                    next_rays.append(ray)\n",
    "                    # color in map to visualize\n",
    "                    np_obs_map[y_coord, x_coord] = 2\n",
    "\n",
    "                    if curr_dist == best_dist:\n",
    "                        curr_ray_angle_delta = norm_ang(ray - float(observation['compass']))\n",
    "                        best_ray_angle_delta = norm_ang(best_ray - float(observation['compass']))\n",
    "                        if abs(curr_ray_angle_delta) > abs(best_ray_angle_delta):\n",
    "                            continue\n",
    "                                            \n",
    "                    best_dist = curr_dist\n",
    "                    best_coord = [y_coord, x_coord]\n",
    "                    best_ray = ray\n",
    "            \n",
    "            if len(next_rays) > 0:\n",
    "                curr_rays = next_rays\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        if best_dist is None:\n",
    "            return None\n",
    "\n",
    "        # color in best ray:\n",
    "        for n_steps in range(int(best_dist // dist_step)):\n",
    "            curr_dist = n_steps * dist_step\n",
    "            y_coord = int(np.cos(best_ray) * curr_dist * 10 + location_in_obs_map[0])\n",
    "            x_coord = int(-np.sin(best_ray) * curr_dist * 10 + location_in_obs_map[1])\n",
    "            np_obs_map[y_coord, x_coord] = 4\n",
    "\n",
    "        self.obstacle_ray_map = np_obs_map\n",
    "        \n",
    "        # translate coord to absolute and relative location\n",
    "        best_gps_coord = np.array([\n",
    "            (y_coord - 200) / 10,\n",
    "            (x_coord - 200) / 10,\n",
    "        ]) + self.start_location\n",
    "\n",
    "        best_relative_coord = best_gps_coord - observation['gps']\n",
    "\n",
    "        rotation_from_start = observation['compass'] - self.start_rotation\n",
    "        # assuming compass is counterclockwise from y+\n",
    "        best_relative_polar_coord = np.array([\n",
    "            np.linalg.norm(best_relative_coord),\n",
    "            # substract 90 deg because arctan is from x+ axis\n",
    "            float((np.arctan2(best_relative_coord[0], best_relative_coord[1]) - np.pi / 2)\n",
    "                  - observation['compass'])\n",
    "        ])\n",
    "        print('start location {}, start rotation {}'.format(\n",
    "            self.start_location, self.start_rotation\n",
    "        ))\n",
    "        print(\n",
    "            '''ray {}, dist {}, coord {}, gps coord {}, my gps {},\n",
    "               my compass {}, relative coord {}, rel polar coord {}'''.format(\n",
    "                best_ray,\n",
    "                max_dist,\n",
    "                best_coord,\n",
    "                best_gps_coord,\n",
    "                observation['gps'],\n",
    "                observation['compass'],\n",
    "                best_relative_coord,\n",
    "                best_relative_polar_coord,\n",
    "            )\n",
    "        )\n",
    "        return best_relative_polar_coord\n",
    "        \n",
    "\n",
    "    def set_offset_to_goal(self, observation):\n",
    "        \"\"\" ID mappings\"\"\"\n",
    "        obj_to_id = {'chair': 0, 'table': 1, 'picture': 2, 'cabinet': 3, 'cushion': 4, 'sofa': 5, 'bed': 6, 'chest_of_drawers': 7, 'plant': 8, 'sink': 9, 'toilet': 10, 'stool': 11, 'towel': 12, 'tv_monitor': 13, 'shower': 14, 'bathtub': 15, 'counter': 16, 'fireplace': 17, 'gym_equipment': 18, 'seating': 19, 'clothes': 20}\n",
    "        id_to_obj = {obj_to_id[key]: key for key in obj_to_id}\n",
    "        if GOAL_SENSOR_UUID == 'objectgoal':\n",
    "            # [distance to goal in metres, angle to goal in radians]\n",
    "            # Take the existing goal and find your offset from it\n",
    "            self.obs[\"pointgoal_with_gps_compass\"] = self.find_object_goal(observation)\n",
    "            if self.obs[\"pointgoal_with_gps_compass\"] is None:\n",
    "                self.obs[\"explorationgoal\"] = self.plan_exploration(observation)\n",
    "                \n",
    "            # doesn't see viable rays. this is not good\n",
    "            if self.obs[\"explorationgoal\"] is None:\n",
    "                print(\"\\n\\nWarning: no viable rays found\\n\\n\")\n",
    "                self.obs[\"explorationgoal\"] = HabitatSimActions.TURN_RIGHT\n",
    "            print('class observation from goal', id_to_obj[observation[GOAL_SENSOR_UUID][0]])\n",
    "\n",
    "            \n",
    "        if self.obs[\"pointgoal_with_gps_compass\"] is not None:\n",
    "            self.located_true_goal = True\n",
    "            self.offset_to_goal = (\n",
    "                    torch.from_numpy(self.obs[\"pointgoal_with_gps_compass\"])\n",
    "                    .float()\n",
    "                    .to(self.device)\n",
    "            )\n",
    "        else:\n",
    "            self.offset_to_goal = (\n",
    "                    torch.from_numpy(self.obs[\"explorationgoal\"])\n",
    "                    .float()\n",
    "                    .to(self.device)\n",
    "            )\n",
    "        print('ostensible observation from goal', self.offset_to_goal)\n",
    "        self.estimatedGoalPos2D = habitat_goalpos_to_mapgoal_pos(\n",
    "            self.offset_to_goal,\n",
    "            self.pose6D.squeeze(),\n",
    "            self.map_cell_size,\n",
    "            self.map_size_meters,\n",
    "        )\n",
    "        self.estimatedGoalPos6D = planned_path2tps(\n",
    "            [self.estimatedGoalPos2D],\n",
    "            self.map_cell_size,\n",
    "            self.map_size_meters,\n",
    "            1.0,\n",
    "        ).to(self.device)[0]\n",
    "        # {'STOP': 0, 'MOVE_FORWARD': 1, 'TURN_LEFT': 2, 'TURN_RIGHT': 3, 'LOOK_UP': 4, 'LOOK_DOWN': 5}\n",
    "        # https://github.com/facebookresearch/habitat-api/blob/master/habitat/sims/habitat_simulator/actions.py\n",
    "        log_attrs = [\n",
    "            'pose6D', 'estimatedGoalPos2D', 'estimatedGoalPos6D', 'action_history', 'cur_time', 'steps'\n",
    "        ]\n",
    "        for attr in log_attrs:\n",
    "            print(attr, getattr(self, attr))\n",
    "        if len(self.position_history) > 0:\n",
    "            print(\"most recent position:\", self.position_history[-1])\n",
    "        print('num obstacles:', self.map2DObstacles.sum())\n",
    "        print('gps and compass:', observation['gps'], observation['compass'])\n",
    "        \n",
    "        # Log the 2D obstacles map and observations\n",
    "        if self.map2DObstacles.sum() > 0:\n",
    "            map_dir = 'maps/' + GOAL_SENSOR_UUID + '_' + str(self.init_time)\n",
    "            if not os.path.exists(map_dir):\n",
    "                os.mkdir(map_dir)\n",
    "            suffix = str(int(time.time())) + '_' + str(int(self.map2DObstacles.sum()))\n",
    "            np.savez_compressed(map_dir + '/obstacle_map_' +\n",
    "                       suffix + '.npz',\n",
    "                       self.map2DObstacles[0,0].cpu().numpy())\n",
    "            if self.obstacle_ray_map is not None:\n",
    "                np.savez_compressed(map_dir + '/obstacle_ray_map_' +\n",
    "                           suffix + '.npz',\n",
    "                           self.obstacle_ray_map)\n",
    "            PIL.Image.fromarray(observation['rgb']).save(map_dir + '/rgb_' + suffix + '.png')\n",
    "            PIL.Image.fromarray(\n",
    "                (observation['depth'] * 255).astype(np.uint8).squeeze(2), 'L'\n",
    "            ).save(map_dir + '/depth_' + suffix + '.png')\n",
    "        return\n",
    "\n",
    "    def rgb_d_from_observation(self, habitat_observation):\n",
    "        rgb = habitat_observation[\"rgb\"]\n",
    "        depth = None\n",
    "        if \"depth\" in habitat_observation:\n",
    "            depth = self.depth_denorm * habitat_observation[\"depth\"]\n",
    "        return rgb, depth\n",
    "\n",
    "    def prev_plan_is_not_valid(self):\n",
    "        if len(self.planned2Dpath) == 0:\n",
    "            return True\n",
    "        pp = torch.cat(self.planned2Dpath).detach().cpu().view(-1, 2)\n",
    "        binary_map = self.map2DObstacles.squeeze().detach() >= self.obstacle_th\n",
    "        obstacles_on_path = (\n",
    "            binary_map[pp[:, 0].long(), pp[:, 1].long()]\n",
    "        ).long().sum().item() > 0\n",
    "        return obstacles_on_path  # obstacles_nearby or  obstacles_on_path\n",
    "\n",
    "    def rawmap2_planner_ready(self, rawmap, start_map, goal_map):\n",
    "        map1 = (rawmap / float(self.obstacle_th)) ** 2\n",
    "        map1 = (\n",
    "            torch.clamp(map1, min=0, max=1.0)\n",
    "            - start_map\n",
    "            - F.max_pool2d(goal_map, 3, stride=1, padding=1)\n",
    "        )\n",
    "        return torch.relu(map1)\n",
    "    \n",
    "    def plan_path(self, overwrite=False):\n",
    "        t = time.time()\n",
    "        if (\n",
    "            (not self.prev_plan_is_not_valid())\n",
    "            and (not overwrite)\n",
    "            and (len(self.planned_waypoints) > 0)\n",
    "        ):\n",
    "            return self.planned2Dpath, self.planned_waypoints\n",
    "        self.waypointPose6D = None\n",
    "        current_pos = self.get_position_on_map()\n",
    "        start_map = torch.zeros_like(self.map2DObstacles).to(self.device)\n",
    "        start_map[\n",
    "            0, 0, current_pos[0, 0].long(), current_pos[0, 1].long()\n",
    "        ] = 1.0\n",
    "        goal_map = torch.zeros_like(self.map2DObstacles).to(self.device)\n",
    "        goal_map[\n",
    "            0,\n",
    "            0,\n",
    "            self.estimatedGoalPos2D[0, 0].long(),\n",
    "            self.estimatedGoalPos2D[0, 1].long(),\n",
    "        ] = 1.0\n",
    "        path, cost = self.planner(\n",
    "            self.rawmap2_planner_ready(\n",
    "                self.map2DObstacles, start_map, goal_map\n",
    "            ).to(self.device),\n",
    "            self.coordinatesGrid.to(self.device),\n",
    "            goal_map.to(self.device),\n",
    "            start_map.to(self.device),\n",
    "        )\n",
    "        if len(path) == 0:\n",
    "            return path, []\n",
    "        if self.timing:\n",
    "            print(time.time() - t, \" s, Planning\")\n",
    "        t = time.time()\n",
    "        planned_waypoints = planned_path2tps(\n",
    "            path, self.map_cell_size, self.map_size_meters, 1.0, False\n",
    "        ).to(self.device)\n",
    "        return path, planned_waypoints\n",
    "\n",
    "    def planner_prediction_to_command(self, p_next):\n",
    "        command = HabitatSimActions.STOP\n",
    "        p_init = self.pose6D.squeeze()\n",
    "        d_angle_rot_th = self.angle_th\n",
    "        pos_th = self.pos_th\n",
    "        if get_distance(p_init, p_next) <= pos_th:\n",
    "            return command\n",
    "        d_angle = norm_ang(\n",
    "            get_direction(p_init, p_next, ang_th=d_angle_rot_th, pos_th=pos_th)\n",
    "        )\n",
    "        if abs(d_angle) < d_angle_rot_th:\n",
    "            command = HabitatSimActions.MOVE_FORWARD\n",
    "        else:\n",
    "            if (d_angle > 0) and (d_angle < pi):\n",
    "                command = HabitatSimActions.TURN_LEFT\n",
    "            elif d_angle > pi:\n",
    "                command = HabitatSimActions.TURN_RIGHT\n",
    "            elif (d_angle < 0) and (d_angle > -pi):\n",
    "                command = HabitatSimActions.TURN_RIGHT\n",
    "            else:\n",
    "                command = HabitatSimActions.TURN_LEFT\n",
    "        return command\n",
    "\n",
    "    def decide_what_to_do(self):\n",
    "        action = None\n",
    "        if self.is_goal_reached():\n",
    "            if self.located_true_goal:\n",
    "                action = HabitatSimActions.STOP\n",
    "            else:\n",
    "                action = HabitatSimActions.TURN_LEFT\n",
    "                self.needs_inspection = True\n",
    "            return {\"action\": action}\n",
    "        if self.unseen_obstacle:\n",
    "            command = HabitatSimActions.TURN_RIGHT\n",
    "            return command\n",
    "        command = HabitatSimActions.STOP\n",
    "        command = self.planner_prediction_to_command(self.waypointPose6D)\n",
    "        return command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym.spaces import Discrete, Box, Tuple\n",
    "\n",
    "\n",
    "class LocalNav(gym.Env):\n",
    "    \"\"\"\n",
    "    RL environment for low-level motion planning.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hab_agent):\n",
    "        self.ha = hab_agent\n",
    "        self.action_space = Discrete(3)  # 0 = forward, 1 = turn left, 2 = turn right (habitat - 1)\n",
    "        self.latest_map = None\n",
    "        self.aloc = None\n",
    "        self.arot = None\n",
    "        self.random_goal = None  # in GPS coordinates\n",
    "        self.observation_space = Tuple((Box(low=np.array([-np.inf] * 3),  # agent loc and rot\n",
    "                                            high=np.array([-np.inf] * 3),\n",
    "                                            dtype=np.float32),\n",
    "                                        Box(low=np.array([-np.inf] * 3),  # map loc and rot\n",
    "                                            high=np.array([-np.inf] * 3),\n",
    "                                            dtype=np.float32),\n",
    "                                        Box(low=np.array([-np.inf, -np.inf]),  # goal loc\n",
    "                                            high=np.array([np.inf, np.inf]),\n",
    "                                            dtype=np.float32),\n",
    "                                        Box(low=0, high=1,  # SLAM obstacle map\n",
    "                                            shape=(1, 400, 400),\n",
    "                                            dtype=np.float32)))\n",
    "\n",
    "    def agent_observation(self):\n",
    "        \"\"\"RL agent's state observation.\"\"\"\n",
    "        return (np.append(self.aloc, self.arot), \n",
    "                self.ha.curr_map_info, \n",
    "                self.random_goal, \n",
    "                self.latest_map)\n",
    "        \n",
    "    def reset(self):\n",
    "        \"\"\"Called at the end of each episode to reset position.\"\"\"\n",
    "        env.reset()\n",
    "        self.ha.reset()\n",
    "        \n",
    "        # Random goal location\n",
    "        rtra = env._sim.sample_navigable_point()\n",
    "        rrot = quaternion.from_euler_angles(np.array([0, 0, 0]))\n",
    "        obs = env._sim.get_observations_at(position=rtra, rotation=rrot, keep_agent_at_new_pose=True)\n",
    "        self.random_goal = obs['gps']\n",
    "        \n",
    "        # Random starting location\n",
    "        rtra = env._sim.sample_navigable_point()\n",
    "        ang = np.random.rand() * 2 * np.pi\n",
    "        rrot = quaternion.from_euler_angles(np.array([0, ang, 0]))\n",
    "        obs = env._sim.get_observations_at(position=rtra, rotation=rrot, keep_agent_at_new_pose=True)\n",
    "        self.aloc, self.arot = obs['gps'], obs['compass']\n",
    "        self.ha.update_internal_state(obs)\n",
    "        \n",
    "        if 'numpy' in str(type(self.ha.map2DObstacles)): \n",
    "            self.latest_map = (self.ha.map2DObstacles > self.ha.obstacle_th).astype(np.uint8)\n",
    "        else:\n",
    "            self.latest_map = (self.ha.map2DObstacles[0,0].cpu().numpy() > self.ha.obstacle_th).astype(np.uint8)\n",
    "            \n",
    "        return self.agent_observation()\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        MDP step.\n",
    "\n",
    "        :param action: 0 forward, 1 turnleft, 2 turnright\n",
    "        :return: state, reward, done (bool), auxiliary info\n",
    "        \"\"\"\n",
    "        \n",
    "        obs = env.step(action + 1)\n",
    "        self.ha.update_internal_state(obs)\n",
    "        self.aloc, self.arot = obs['gps'], obs['compass']\n",
    "        \n",
    "        if 'numpy' in str(type(self.ha.map2DObstacles)): \n",
    "            self.latest_map = (self.ha.map2DObstacles > self.ha.obstacle_th).astype(np.uint8)\n",
    "        else:\n",
    "            self.latest_map = (self.ha.map2DObstacles[0,0].cpu().numpy() > self.ha.obstacle_th).astype(np.uint8)\n",
    "            \n",
    "            \n",
    "        reward = -1  # time-minimizing reward\n",
    "        done = np.linalg.norm(self.aloc - self.random_goal) < 0.5  # reached goal\n",
    "        return self.agent_observation(), reward, done, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256])\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "from stable_baselines3.common.policies import ActorCriticPolicy\n",
    "\n",
    "class MyFeatureExtractor(nn.Module):\n",
    "    \n",
    "    def __init__(self, observation_space: gym.Space, features_dim: int = 256):\n",
    "        super(MyFeatureExtractor, self).__init__()\n",
    "        self.cnn = nn.Sequential(nn.Conv2d(1, 32, kernel_size=5, stride=2, padding=0),\n",
    "                                 \n",
    "                                 nn.MaxPool2d(2),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=0),\n",
    "                                 nn.MaxPool2d(2), \n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=0),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=0),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.AdaptiveAvgPool2d((1, 1)))  # b, 256, 1, 1\n",
    "        self.features_dim = features_dim\n",
    "        self.linear = nn.Sequential(nn.Linear(256 + 8, features_dim), nn.ReLU())\n",
    "    \n",
    "    def forward(self, observations):\n",
    "        agent_info, map_info, goal_info, latest_map = observations\n",
    "        map_features = self.cnn(latest_map).reshape(agent_info.shape[0], 256)\n",
    "        return self.linear(torch.cat([map_features, agent_info, map_info, goal_info], dim=1))\n",
    "        \n",
    "\n",
    "class MyPolicy(ActorCriticPolicy):\n",
    "\n",
    "    def __init__(self,\n",
    "                 observation_space: gym.spaces.Space,\n",
    "                 action_space: gym.spaces.Space,\n",
    "                 lr_schedule: Callable,\n",
    "                 net_arch: Optional[List[Union[int, Dict[str, List[int]]]]] = None,\n",
    "                 device: Union[th.device, str] = 'auto',\n",
    "                 activation_fn: Type[nn.Module] = nn.Tanh,\n",
    "                 ortho_init: bool = True,\n",
    "                 use_sde: bool = False,\n",
    "                 log_std_init: float = 0.0,\n",
    "                 full_std: bool = True,\n",
    "                 sde_net_arch: Optional[List[int]] = None,\n",
    "                 use_expln: bool = False,\n",
    "                 squash_output: bool = False,\n",
    "                 features_extractor_class: Type[BaseFeaturesExtractor] = MyFeatureExtractor,\n",
    "                 features_extractor_kwargs: Optional[Dict[str, Any]] = None,\n",
    "                 normalize_images: bool = True,\n",
    "                 optimizer_class: Type[th.optim.Optimizer] = th.optim.Adam,\n",
    "                 optimizer_kwargs: Optional[Dict[str, Any]] = None):\n",
    "\n",
    "        if optimizer_kwargs is None:\n",
    "            optimizer_kwargs = {}\n",
    "            # Small values to avoid NaN in ADAM optimizer\n",
    "            if optimizer_class == th.optim.Adam:\n",
    "                optimizer_kwargs['eps'] = 1e-5\n",
    "\n",
    "        super(ActorCriticPolicy, self).__init__(observation_space,\n",
    "                                                action_space,\n",
    "                                                device,\n",
    "                                                features_extractor_class,\n",
    "                                                features_extractor_kwargs,\n",
    "                                                optimizer_class=optimizer_class,\n",
    "                                                optimizer_kwargs=optimizer_kwargs,\n",
    "                                                squash_output=squash_output)\n",
    "\n",
    "        # Default network architecture, from stable-baselines\n",
    "        if net_arch is None:\n",
    "            if features_extractor_class == FlattenExtractor:\n",
    "                net_arch = [dict(pi=[64, 64], vf=[64, 64])]\n",
    "            else:\n",
    "                net_arch = []\n",
    "\n",
    "        self.net_arch = net_arch\n",
    "        self.activation_fn = activation_fn\n",
    "        self.ortho_init = ortho_init\n",
    "\n",
    "        self.features_extractor = features_extractor_class(self.observation_space,\n",
    "                                                           **self.features_extractor_kwargs)\n",
    "        self.features_dim = self.features_extractor.features_dim\n",
    "\n",
    "        self.normalize_images = normalize_images\n",
    "        self.log_std_init = log_std_init\n",
    "        dist_kwargs = None\n",
    "        # Keyword arguments for gSDE distribution\n",
    "        if use_sde:\n",
    "            dist_kwargs = {\n",
    "                'full_std': full_std,\n",
    "                'squash_output': squash_output,\n",
    "                'use_expln': use_expln,\n",
    "                'learn_features': sde_net_arch is not None\n",
    "            }\n",
    "\n",
    "        self.sde_features_extractor = None\n",
    "        self.sde_net_arch = sde_net_arch\n",
    "        self.use_sde = use_sde\n",
    "        self.dist_kwargs = dist_kwargs\n",
    "\n",
    "        # Action distribution\n",
    "        self.action_dist = make_proba_distribution(action_space, use_sde=use_sde, dist_kwargs=dist_kwargs)\n",
    "\n",
    "        self._build(lr_schedule)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\n",
    "    \"--agent-type\",\n",
    "    default=\"orbslam2-rgbd\",\n",
    "    choices=[\"blind\", \"orbslam2-rgbd\", \"orbslam2-rgb-monod\"],\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--task-config\", type=str, default=\"tasks/pointnav_rgbd.yaml\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--goal-sensor-uuid\", type=str, default=\"pointgoal_with_gps_compass\"\n",
    ")\n",
    "args = parser.parse_args([\n",
    "    \"--task-config\", \"configs/tasks/objectnav_mp3d_fast.yaml\",\n",
    "    \"--goal-sensor-uuid\", \"objectgoal\"\n",
    "])\n",
    "\n",
    "global GOAL_SENSOR_UUID\n",
    "GOAL_SENSOR_UUID = args.goal_sensor_uuid\n",
    "\n",
    "config = get_config()\n",
    "agent_config = cfg_baseline()\n",
    "agent_config.defrost()\n",
    "config.defrost()\n",
    "config.ORBSLAM2 = agent_config.ORBSLAM2\n",
    "#config.BASELINE = agent_config.BASELINE\n",
    "make_good_config_for_orbslam2(config)\n",
    "\n",
    "if args.agent_type == \"blind\":\n",
    "    agent = BlindAgent(config.ORBSLAM2)\n",
    "elif args.agent_type == \"orbslam2-rgbd\":\n",
    "    agent = ORBSLAM2Agent(config.ORBSLAM2)\n",
    "elif args.agent_type == \"orbslam2-rgb-monod\":\n",
    "    agent = ORBSLAM2MonodepthAgent(config.ORBSLAM2)\n",
    "else:\n",
    "    raise ValueError(args.agent_type, \"is unknown type of agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-02 00:41:18,081 Initializing dataset ObjectNav-v1\n",
      "2020-06-02 00:41:18,116 initializing sim Sim-v0\n",
      "I0602 00:41:24.561522 21723 simulator.py:142] Loaded navmesh data/scene_datasets/mp3d/x8F5xyUWy9e/x8F5xyUWy9e.navmesh\n",
      "2020-06-02 00:41:24,569 Initializing task ObjectNav-v1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original number of episodes: 30\n"
     ]
    }
   ],
   "source": [
    "task_config = habitat.get_config(config_paths=args.task_config)\n",
    "env = None\n",
    "env = habitat.Env(config=task_config)\n",
    "print(\"original number of episodes:\", len(env.episodes))\n",
    "env.episodes = [env.episodes[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3) (480, 640, 1) [3] [2.9111131e-09] [-0.  0.]\n"
     ]
    }
   ],
   "source": [
    "observations = env.reset()\n",
    "print(\n",
    "    observations['rgb'].shape, observations['depth'].shape, observations['objectgoal'], \\\n",
    "    observations['compass'], observations['gps']\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "habitat",
   "language": "python",
   "name": "habitat"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
